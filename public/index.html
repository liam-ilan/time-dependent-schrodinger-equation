<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Visualizing the Impossible</title>
    <link rel="stylesheet" href="./style.css">
    <link rel="shortcut icon" href="favicon.png" type="image/x-icon">
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <meta name="author" content="Liam Ilan">
    <meta
      name="description"
      content="Visualizing the Impossible - Numerically Approximating the Time Dependent Schrödinger Equation for Computer Visualization"
    />
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body>
    <div id="container">
      <h1>Visualizing the Impossible</h1>
      <h5>
        Numerically Approximating the Time Dependent Schrödinger Equation for Computer Visualization
      </h5>
      <h6>By Liam Ilan</h6>
      <hr />

      <p>
        Some things don’t make sense. Here’s an example:
        <div class="emphasis center">Light is both a particle and a wave</div>
      </p>

      <p>
        When I first heard this, it just didn’t sit right. It seemed as absurd as saying that something can be both blue and brown, or that a ball can tunnel through a wall, or that <a href="https://en.wikipedia.org/wiki/Schr%C3%B6dinger%27s_cat">a cat can be both alive and dead at the same time</a>.
      </p>

      <p>
        This article's goal is to make sense of this conundrum. In the proccess, we will learn how to use the finite difference method to numerically approximate the time dependent Schrödinger equation. Such approximations are used to make animations like:
      </p>
    
      <p class="image">
        <video src="animations/quartic/video.mp4" poster="animations/quartic/thumbnail.png" controls></video>
        <div class="subtitle">A gaussian wave packet interacting with a quartic potential. The green and yellow dotted lines represent the real and imaginary components of the wave function respectively. The blue line represents the probability distribution of the wave function. The red line represents the potential. We will learn what all of these terms mean throughout the article.</div>
      </p>

      <h2>The Wave Function</h2>

      <p>
        Let’s start with the statement above, <span class="emphasis">light is both a particle and a wave</span>. What do we mean by this?
      </p>

      <p>
        Photons, electrons, and in fact all elementary particles, are like disturbances in a pond. They exhibit wave phenomena (relection, diffraction, interference, doppler effect, etc.). This "pond", that an elementary particle exists in, is called a quantum field, and it exists all around us.
      </p>

      <p>
        These disturbances in the field, also known as matter waves, are described by the complex valued wave function, \(\psi(x, t)\). The magnitude of this wave function is related to how likely we are to observe a particle at any given position. More specifically, the probability distribution function describing the position of the particle is,

        $$|\psi(x, t)|^2$$
      </p>

      <p class="image">
        <img src="./assets/orbital.png"></img>
        <div class="subtitle">The Probability Distribution of a 4f Electron. The electron does not exist at any single position, until it is observed. This graph was generated as part of a seperate project by the author, and can be found <a href="https://liam-ilan.github.io/electron-orbitals/">here</a>.</div>
      </p>

      <p class="image">
        <img src="./assets/snapshot-stationary.png"></img>
        <div class="subtitle">A snapshot of an arbitrary matter wave. The blue line is the probability distribution. The green and yellow lines are the real and imaginary components of the wave. The red line represents the potential (here it is 0). This shows how the matter wave itself relates to finding the particle at any given position.</div>
      </p>

      <p>
        It thus makes sense that \(|\psi(x, t)|^2\) should follow the same rules that probability distribution functions do. Specifically, the the sum of all probabilities that the particle is observed at any given point, must be equal to 100%, or

        $$\int_{-\infty}^{\infty} |\psi(x, t)|^2 \,\partial{x} = 1$$

        We will use this property later on to increase the accuracy of our animations.
      </p>

      <h3>The Schrödinger Equation</h3>

      <p>
        But how do we find valid matter waves to animate? Valid solutions to the wave function can be found via the time dependent Schrödinger equation,

        $$i \hbar \frac{\partial}{\partial t} \psi(x, t) = -\frac{\hbar}{2m} \frac{\partial^2}{{\partial x}^2} \psi(x,t) + V(x)\psi(x,t)$$

        where \(\psi(x, t)\) is the wave function, \(\hbar\) is the reduced planck's constant, \(m\) is the mass of the particle, and \(V(x)\) is the potential energy at a given point \(x\).
      </p>

      <p class="note">
        Deriving this equation is not within the scope of this article, however, an excellent resource on the topic can be found <a href="https://www.cantorsparadise.com/the-origins-of-the-schr%C3%B6dinger-equation-47bdfddced17">here</a>.
      </p>

      <p>
        The time dependent Schrödinger equation appears extremely daunting, and if you’re like me, solving it seems impossible. Luckily, we don’t need to solve it. If we set the problem up correctly, we can let a computer do it for us.
      </p>

      <h3>Potential Energy</h3>

      <p>
        Before we try to solve the Schrödinger equation, we have one last term to define, \(V(x)\). We said earlier that \(V(x)\) is the potential energy at a given point, but what does that mean?
      </p>

      <p>
        Let’s go back to classical physics, a ball, and a hill.
      </p>

      <p class="image">
        <img src="./assets/balls-on-hill.svg"></img>
        <div class="subtitle">Many balls, at different horizontal displacements, on a hill. We can calculate the potential energy of each of these balls, and plot it.</div>
      </p>

      <p>
        At any point in space, we can calculate the potential energy of the ball, as a function of horizontal displacement,

        $$V(x) = mgh(x)$$
      </p>

      <p class="image">
        From there, we can plot the potential energy,
        
      </p>

      <p class="image">
        <img src="./assets/potential-graph.svg"></img>
        <div class="subtitle">Potential Energy Graph</div>
      </p>

      <p>
        Notice how \(V(x)\) represents how much energy is needed to get from a point of \(0\) potential, to a point \(x\). A point with a higher potential requires more energy to get to.
      </p>

      <p>
        In the Schrödinger equation, \(V(x)\) is similar to the above example. We are still representing the quantity of potential energy, however this time, instead of having a hill, we might have an insulating layer, stopping current in a circuit. This insulating layer would have a higher potential, as more energy is required to move through it.
      </p>

      <p>
        One of the important things to note is that the term \(V(x)\) is potential energy, not voltage. Voltage measures a quantity of energy per charge. Here, we measure a quantity of energy, period.
      </p>

      <p class="image">
        <video src="animations/barrier/video.mp4" poster="animations/barrier/thumbnail.png" controls></video>
        <div class="subtitle">An electron bounces off of a potential barrier (in red), as it does not have enough energy to get across.</div>
      </p>

      <p>
        At the start of the animation, the probability distribution appears normal (blue line). When the particle hits the barrier, various partterns appear in the probability distribution as a result of the reflection wave phenomenon exhibited by the matter wave (in green and yellow).
      </p>

      <h2>Approximating the Schrödinger Equation</h2>

      <p>
        Now that we have defined all our terms, let’s go back to the Schrödinger Equation,

        $$i \hbar \frac{\partial}{\partial t} \psi(x, t) = -\frac{\hbar}{2m} \frac{\partial^2}{{\partial x}^2} \psi(x,t) + V(x)\psi(x,t)$$

        This is a second order partial differential equation, and while we could try to find exact analytical solutions, it seems like a lot of work... So let’s not do that!
      </p>

      <p>
        Instead, we can find approximate solutions, that, for the sake of animations, are indistinguisable from the analytical result. <span class="emphasis">It’s good enough, to be close enough.</span>
      </p>

      <h3>The Finite Difference Method</h3>

      <p>
        The goal of the Finite Difference Method, is to take continuous derivatives, such as those found in the Schrödinger equation, (\(\frac{\partial}{\partial t} \psi(x, t)\) and \(\frac{\partial^2}{{\partial x}^2} \psi(x,t)\)), and transform them into discrete, computable functions.
      </p>

      <p>
        To do this, let’s go back to fundamentals, with the definition of a derivative,

        $$\frac{d}{dx} f(x) = \lim_{\Delta x \to 0} \frac{f(x + \Delta x) - f(x)}{\Delta x}$$
      </p>

      <p>
        In this definition of the derivative, we use infinitesimally small values of x. The problem is that we can’t do that on a computer. What we can do however, is use very very small, finite steps, to approximate the derivative. This is where the “Finite Difference Method” gets its namesake.
      </p>

      <p>
        We can use this to find the first time derivative of the wave function, present on the left side of the Schrödinger equation,

        $$\frac{\partial}{\partial t} \psi(x, t) = \lim_{\Delta t \to 0} \frac{\psi(x, t + \Delta t) - \psi(x, t)}{\Delta t}$$
      </p>
      <p>
        Now, let's take the second spatial derivative present on the right hand side of the Schrödinger equation. The first step, is to find the first spatial derivative. Let’s repeat the same process we did for the time derivative,

        $$\frac{\partial}{\partial x} \psi(x, t) = \lim_{\Delta x \to 0} \frac{\psi(x + \Delta x, t) - \psi(x, t)}{\Delta x}$$
      </p>

      <p>
        Uh oh... we have a small problem here. In our animation, time only moves one way (forward), so we can say it behaves asymmetrically. In contrast, space in our animation exists in two directions (\(+x\) and \(-x\)). The derivative we have been working with so far has been asymmetric. Before we can move forward, we will need a symmetric definition for the derivative,

        $$\frac{d}{dx} f(x) = \lim_{\Delta x \to 0} \frac{f(x + \Delta x) - f(x - \Delta x)}{2 \Delta x}$$

        You will find that this definition is, for infinitesimally small steps, identical to our first definition (minus a few edge cases), however for finite steps, this definition is spatially symmetric.
        
      </p>

      <p class="image">
        <img src="./assets/diff-1.png"></img>
        <div class="subtitle">The asymmetric derivative illustrated. Asymmetric derivatives are biased towards the positive end of the value we want to measure a derivative for.</div>
      </p>

      <p class="image">
        <img src="./assets/diff-2.png"></img>
        <div class="subtitle">The symmteric derivative illustrated. Symmetric derivatives test both in the positive and negative direction, and thus are not biased towards any particular direction.</div>
      </p>

      <p> 
        Now, we can find the first spatial derivative of \(\psi(x,t)\), 

        $$\text{let } D(x, t) = \frac{\partial}{\partial x} \psi(x, t) = \lim_{\Delta x \to 0} \frac{\psi(x + \Delta x, t) - \psi(x - \Delta x, t)}{2 \Delta x}$$

        And the second derivative,

        $$ \begin{aligned}
        \frac{\partial^2}{{\partial x}^2} \psi(x, t)
        &=\frac{\partial}{\partial x} D(x, t)\\
        &=\lim_{\Delta x \to 0} \frac{D(x + \Delta x, t) - D(x - \Delta x, t)}{2 \Delta x} \\
        &= \lim_{\Delta x \to 0} \frac{\frac{\psi(x + 2\Delta x, t) - \psi(x, t)}{2 \Delta x} - \frac{\psi(x, t) - \psi(x - 2 \Delta x, t)}{2 \Delta x}}{2 \Delta x} \\
        &= \lim_{\Delta x \to 0} \frac{\psi(x + 2 \Delta x, t) - 2 \psi(x, t) + \psi(x - 2 \Delta x, t)}{4 {\Delta x}^2} \\
        &= \lim_{\Delta x \to 0} \frac{\psi(x + \Delta x, t) - 2 \psi(x, t) + \psi(x - \Delta x, t)}{{\Delta x}^2} \\
        \end{aligned} $$
      </p>

      <p>
        From here on out, we will drop the limits to reflect the fact that we are using finite steps.
      </p>

      <p>
        We can now rewrite the Schrödinger equation with our substitutes for the derivative.

        $$
        i \hbar \frac{\psi(x, t + \Delta t) - \psi(x, t)}{\Delta t} = -\frac{\hbar}{2m} \left( \frac{\psi(x + \Delta x, t) - 2 \psi(x, t) + \psi(x - \Delta x, t)}{{\Delta x}^2} \right) + V(x)\psi(x,t)
        $$
      </p>

      <p>
        And then rearrange this formula, such that \(\psi(x, t + \Delta t)\) is isolated,

        $$
        \begin{aligned}
        \psi(x, t + \Delta t) &= \left(\frac{1}{2m} \right) \left(\frac{\Delta t}{{\Delta x}^2} \right) \left( \psi(x + \Delta x, t) - 2 \psi(x, t) + \psi(x - \Delta x, t) \right) \\
        &- \left(\frac{i}{\hbar}\right)(\Delta t)V(x)\psi(x,t) \\
        &+ \psi(x,t)
        \end{aligned}
        $$
      </p>

      <p>
        This formula let's us predict the value of \(\psi\) (the wave function) in a future timestep, in terms of the current state of \(\psi\). By recursively applying this formula, we can obtain wave functions further than one timestep away.
      </p>

      <h3>Initial Value</h3>

      <p>
        But what about that initial value? The algorithm we built let's us calculate states of \(\psi\) in terms of it's past states, but at \(t=0\), there is no past state of \(\psi\). We need some some set of initial conditions that represents the information we have on the particle at \(t=0\).
      </p>
      
      <p>
        A commonly used initial value is the Gaussian Wave Packet. The Gaussian Wave Packet has a very important property that makes it a good choice for initial conditions, which is that taking the magnitude of the gaussian wave packet, and squaring it, results in a normal probability distribution, thus, if we were to observe a particle at some position \(x_0\), this distribution would tell us how likely we would be to find the particle again at any point \(x\). Because of this, it reflects the initial information we have on the particle. The formula for the Gaussian Wave Packet is,

        $$\psi(x, 0) = \left(e^{ikx}\right)\left(e^{-\frac{1}{2}\left({\frac{x-x_0}{\sigma}}\right)^2}\right)$$

        where \(\sigma\) is the standard deviation of the wave packet, \(x_0\) is the initial mean, and \(k\) is the wave number.
      </p>

      <p>
        The wave number (\(k\)) is important for a couple of reasons. First, it is linearly correlated to the momentum of the particle,
        $$p = \hbar k$$

        Second, it is inversely proportional the wavelength of the particle,
        $$k = \frac{2 \pi}{\lambda}$$

        A negative \(k\) will result in momentum in the negative direction, and a positive \(k\) will result in momentum in a positive direction.
      </p>

      <p class="image">
        <video src="animations/stationary/video.mp4" poster="animations/stationary/thumbnail.png" controls></video>
        <div class="subtitle">An animation where \(k = 0\). Because of this, the wave packet is stationary, and the initial wavelength is \(\infty\) (which can be seen through the lack of periodicity in the initial wave packet). </div>
      </p>

      <p class="image">
        <video src="animations/free/video.mp4" poster="animations/free/thumbnail.png" controls></video>
        <div class="subtitle">Animation where \(k > 0\). Because of this, the wavepacket's wavelength is much shorter than when \(k = 0\). Additionally, the particle has momentum to the right due to a positive \(k\).</div>
      </p>

      <h2>Kinks in the System</h2>

      <p>
        While theoretically correct, the math above is not enough to approximate the time dependent Schrödinger equation. We are missing two more components to our solution, normalization, and boundary conditions.
      </p>

      <h3>Normalization</h3>

      <p>
        One limitation of real computers is that numbers and operations are not always percise, as computers are constrained with how much memory they can assign to any given number. As we recursively apply our algorithm, numerical instability will arise, thus the condition we laid out at the very start of this article,
        $$\int_{-\infty}^{\infty} |\psi(x, t)|^2 \,\partial{x} = 1$$

        may no longer hold true.
      </p>

      <p>
        In order to correct for this, after each application of our algorithm, we normalize \(\psi\). The process is as follows,

        $$ \text{let } \psi_0 = \text{the resulting wave function after an iteration of our algorithm} $$
        $$ \text{let } I = \int_{-\infty}^{\infty} |\psi_0(x, t)|^2 \,\partial{x} $$

        We can rearrange this,

        $$I^{-1}\int_{-\infty}^{\infty} |\psi_0(x, t)|^2 \,\partial{x} = 1$$
        $$\int_{-\infty}^{\infty} \frac{|\psi_0(x, t)|^2}{I} \,\partial{x} = 1$$

        Thus,
        $$\int_{-\infty}^{\infty} \frac{|\psi_0(x, t)|^2}{I} \,\partial{x} = \int_{-\infty}^{\infty} |\psi(x, t)|^2 \,\partial{x} = 1$$

        Dropping the integrals,
        $$\frac{|\psi_0(x, t)|^2}{I} = |\psi(x, t)|^2$$
        $$\frac{|\psi_0(x, t)|}{\sqrt{I}} = |\psi(x, t)|$$

        Since \(I \in \mathbb{R}\),
        $$\frac{\psi_0(x, t)}{\sqrt{I}} = \psi(x, t)$$
      </p>

      <p>
        After every single calculation using our algorithm, we can compute the resulting integral, \(I\), and apply this normalization to obtain a more accurate result, correcting for minor numerical instability.
      </p>

      <h3>Boundary Conditions</h3>

      <p>
        In the math world, we can say that the domain of \(\psi(x,t)\) is infinite. In the computer world, however, we don’t have infinite memory, so we need to set bounds to our simulation.
      </p>

      <p>
        There is a problem however, when attempting to evaluate \(\psi\) at a boundary.
      </p>

      <p>
        Let’s take an example, set our left most boundary (the negative direction) to \(0\), and then try to evaluate \(\psi(0, t + \Delta t)\),

        $$
        \begin{aligned}
        \psi(0, t + \Delta t) &= \left(\frac{1}{2m} \right) \left(\frac{\Delta t}{{\Delta x}^2} \right) \left( \psi(\Delta x, t) - 2 \psi(0, t) + \psi(-\Delta x, t) \right) \\ 
        &- \left(\frac{i}{\hbar}\right)(\Delta t)V(0)\psi(0,t) \\
        &+ \psi(0,t)
        \end{aligned}
        $$

        In order to find \(\psi(0, t + \Delta t)\), we need to know \(\psi(-\Delta x, t)\), however, since \(-\Delta x\ \lt 0\), \(-\Delta x\) is outside the bounds of the wave function. How do we handle this?
      </p>

      <p>
        Well, it turns out that there are a couple ways, none of which are correct or incorrect. For the animations present in this article, it is assumed that \(\psi\) at the boundary is \(0\). There are many other valid boundary conditions, including purely reflective, absorptive, and ring boundary conditions. The topic of other boundary conditions is a bit beyond the scope of this article, however is an excellent jumping off point for future work.
      </p>

      <h2>Some Cool Results</h2>

      <p>
        The algorithm described above is implemented in Python and Matplotlib <a href="https://github.com/liam-ilan/time-dependent-schrodinger-equation">here</a>.
        
        Here are some interesting animations generated with the software,
      </p>

      <p class="image">
        <video src="animations/barrier/video.mp4" poster="animations/barrier/thumbnail.png" controls></video>
        <div class="subtitle">A high energy potential barrier reflects an electron completely.</div>
      </p>

      <p class="image">
        <video src="animations/double/video.mp4" poster="animations/double/thumbnail.png" controls></video>
        <div class="subtitle">An electron tunnels through two barriers.</div>
      </p>

      <p class="image">
        <video src="animations/free/video.mp4" poster="animations/free/thumbnail.png" controls></video>
        <div class="subtitle">A free electron.</div>
      </p>

      <p class="image">
        <video src="animations/oscillator/video.mp4" poster="animations/oscillator/thumbnail.png" controls></video>
        <div class="subtitle">An electron in a quadratic potential oscillates with simple harmonic motion.</div>
      </p>

      <p class="image">
        <video src="animations/quartic/video.mp4" poster="animations/quartic/thumbnail.png" controls></video>
        <div class="subtitle">An electron interacts with a quartic potential.</div>
      </p>

      <p class="image">
        <video src="animations/stationary/video.mp4" poster="animations/stationary/thumbnail.png" controls></video>
        <div class="subtitle">An electron with no momentum.</div>
      </p>

      <h2>Finally...</h2>
      
      <p>
        Let's visualize the impossible.
      </p>

      <p>
        In classical physics, a hill with more potential energy than a particle will always stop the particle from passing.
      </p>

      <p class="image">
        <img src="./assets/balls-no-pass.svg"></img>
        <div class="subtitle">The potential energy of the hill is too high for the ball to pass.</div>
      </p>

      <p>
        In quantum mechanics however, this is not always the case.
      </p>

      <p class="image">
        <video src="animations/tunnel/video.mp4" poster="animations/tunnel/thumbnail.png" controls></video>
        <div class="subtitle">Quantum tunneling.</div>
      </p>

      <p>
        What we observe here, is a particle with some energy, colliding with a barrier of significantly higher potential. Rather than the the particle being completely reflected, the particle has some probability of "tunneling" through the barrier. We call this phenomenon, quantum tunneling, one of the many cases where quantum physics makes the impossible, possible.
      </p>

      <h2>References</h2>

      <p>
        <div class="citation-item">
          Cantor's Paradise (2023, February 3). The Origins of the Schrödinger Equation. Medium. Retrieved June 6, 2023, from <a href="https://www.cantorsparadise.com/the-origins-of-the-schr%C3%B6dinger-equation-47bdfddced17">https://www.cantorsparadise.com/the-origins-of-the-schr%C3%B6dinger-equation-47bdfddced17</a>
        </div>
        <div class="citation-item">
          Finite difference method. (2023, February 11). In Wikipedia. <a href="https://en.wikipedia.org/wiki/Finite_difference_method">https://en.wikipedia.org/wiki/Finite_difference_method</a>
        </div>
        <div class="citation-item">
          [Mr. P Solver]. (2023, June 21). Time-Dependent Schrodinger Equation in Python: Two Different Techniques [Video]. Youtube. <a href="https://youtu.be/kVjg3jbM3Pw">https://youtu.be/kVjg3jbM3Pw</a>
        </div>
        <div class="citation-item">
          Rectangular potential barrier. (2023, February 27). In Wikipedia. <a href="https://en.wikipedia.org/wiki/Rectangular_potential_barrier">https://en.wikipedia.org/wiki/Rectangular_potential_barrier</a>
        </div>
        <div class="citation-item">
          Schwartz, M. Lecture 11: Wavepackets and dispersion [PDF]. Harvard. <a href="https://scholar.harvard.edu/files/schwartz/files/lecture11-wavepackets.pdf">https://scholar.harvard.edu/files/schwartz/files/lecture11-wavepackets.pdf</a>
        </div>
        <div class="citation-item">
          Symmetric derivative. (2023, March 25). In Wikipedia. <a href="https://en.wikipedia.org/wiki/Symmetric_derivative">https://en.wikipedia.org/wiki/Symmetric_derivative</a>
        </div>
      </p>

      <p>
        The software to generate all the animations for this article can be found <a href="https://github.com/liam-ilan/time-dependent-schrodinger-equation">here</a>.
      </p>

      <p id="copyright">
        Copyright © 2023 <a href="https://www.liamilan.com/">Liam Ilan</a> <br />
        Written for <a href="https://some.3b1b.co/">SoME3</a>
      </p>
    </div>
  </body>
</html>